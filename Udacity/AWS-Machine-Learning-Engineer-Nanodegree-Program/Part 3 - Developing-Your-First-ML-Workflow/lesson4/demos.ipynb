{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demos\n",
    "\n",
    "This is the notebook containing the demos for Feature Store, Model Monitor, and Clarify. Testing for these exercises was performed using __2 vCPU + 4 GiB notebook instance with Python 3 (TensorFlow 2.1 Python 3.6 CPU Optimized) kernel__.\n",
    "\n",
    "## Staging\n",
    "\n",
    "We'll begin by initializing some variables that are used throughout the demos. These are often assumed to be present in code samples you'll find in the AWS documenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Store\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature store is a special database to give ML systems a consistent data flow across training and inference workloads. It can ingest data in batches (for training) as well as serve input features to models with very low latency for real-time prediction.\n",
    "\n",
    "For this demo we'll use the boston housing dataset, which you can learn more about here: https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data(test_split=0.1, seed=1234)\n",
    "\n",
    "# Manually add headers\n",
    "train_headers = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"]\n",
    "test_headers = [\"MEDV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "\n",
    "boston_train = pd.DataFrame(x_train, columns=train_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our data, we can create a feature group. Remember to attach event time and ID columns - Feature Store needs them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeatureDefinition(feature_name='CRIM', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='ZN', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='INDUS', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='CHAS', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='NOX', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='RM', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='AGE', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='DIS', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='RAD', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='TAX', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='PTRATIO', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='B', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='LSTAT', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='EventTime', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='id', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_train[\"EventTime\"] = time.time()\n",
    "boston_train[\"id\"] = range(len(boston_train))\n",
    "\n",
    "# Create feature group\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "feature_group = FeatureGroup(\n",
    "    name=\"boston-features\", sagemaker_session=session\n",
    ")\n",
    "\n",
    "# Load Feature definitions\n",
    "feature_group.load_feature_definitions(data_frame=boston_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature group is not created until we call the `create` method, let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group.create(\n",
    "    s3_uri=f\"s3://{bucket}/features\",\n",
    "    record_identifier_name='id',\n",
    "    event_time_feature_name=\"EventTime\",\n",
    "    role_arn=role,\n",
    "    enable_online_store=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For applications, we can create a lightweight client to retrieve data with low latency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = session.boto_session.client(\n",
    "  'sagemaker-featurestore-runtime',\n",
    "  region_name=region\n",
    ")\n",
    "\n",
    "data = runtime.get_record(\n",
    "    FeatureGroupName=\"boston-features\",\n",
    "    RecordIdentifierValueAsString=\"0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to get records before we ingest any data, the response comes back empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IngestionManagerPandas(feature_group_name='boston-features', sagemaker_session=<sagemaker.session.Session object at 0x7fa28b652f60>, data_frame=         CRIM    ZN  INDUS  CHAS     NOX     RM    AGE     DIS   RAD    TAX  \\\n",
       "0     0.01951  17.5   1.38   0.0  0.4161  7.104   59.5  9.2229   3.0  216.0   \n",
       "1     0.14866   0.0   8.56   0.0  0.5200  6.727   79.9  2.7778   5.0  384.0   \n",
       "2    25.04610   0.0  18.10   0.0  0.6930  5.987  100.0  1.5888  24.0  666.0   \n",
       "3     3.67367   0.0  18.10   0.0  0.5830  6.312   51.9  3.9917  24.0  666.0   \n",
       "4     9.51363   0.0  18.10   0.0  0.7130  6.728   94.1  2.4961  24.0  666.0   \n",
       "..        ...   ...    ...   ...     ...    ...    ...     ...   ...    ...   \n",
       "450  18.81100   0.0  18.10   0.0  0.5970  4.628  100.0  1.5539  24.0  666.0   \n",
       "451   8.49213   0.0  18.10   0.0  0.5840  6.348   86.1  2.0527  24.0  666.0   \n",
       "452   4.66883   0.0  18.10   0.0  0.7130  5.976   87.9  2.5806  24.0  666.0   \n",
       "453   0.31827   0.0   9.90   0.0  0.5440  5.914   83.2  3.9986   4.0  304.0   \n",
       "454   0.12757  30.0   4.93   0.0  0.4280  6.393    7.8  7.0355   6.0  300.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT     EventTime   id  \n",
       "0       18.6  393.24   8.05  1.630619e+09    0  \n",
       "1       20.9  394.76   9.42  1.630619e+09    1  \n",
       "2       20.2  396.90  26.77  1.630619e+09    2  \n",
       "3       20.2  388.62  10.58  1.630619e+09    3  \n",
       "4       20.2    6.68  18.71  1.630619e+09    4  \n",
       "..       ...     ...    ...           ...  ...  \n",
       "450     20.2   28.79  34.37  1.630619e+09  450  \n",
       "451     20.2   83.45  17.64  1.630619e+09  451  \n",
       "452     20.2   10.48  19.01  1.630619e+09  452  \n",
       "453     18.4  390.70  18.33  1.630619e+09  453  \n",
       "454     16.6  374.71   5.19  1.630619e+09  454  \n",
       "\n",
       "[455 rows x 15 columns], max_workers=3, _futures={<Future at 0x7fa24f6c6668 state=finished returned NoneType>: (0, 152), <Future at 0x7fa24f6c6438 state=finished returned NoneType>: (152, 304), <Future at 0x7fa24f65b278 state=finished returned NoneType>: (304, 455)})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group.ingest(data_frame=boston_train, max_workers=3, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '6c8103a0-0630-439b-ab7a-42d671bc65a1',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '6c8103a0-0630-439b-ab7a-42d671bc65a1',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '718',\n",
       "   'date': 'Thu, 02 Sep 2021 21:41:19 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Record': [{'FeatureName': 'CRIM', 'ValueAsString': '0.01951'},\n",
       "  {'FeatureName': 'ZN', 'ValueAsString': '17.5'},\n",
       "  {'FeatureName': 'INDUS', 'ValueAsString': '1.38'},\n",
       "  {'FeatureName': 'CHAS', 'ValueAsString': '0.0'},\n",
       "  {'FeatureName': 'NOX', 'ValueAsString': '0.4161'},\n",
       "  {'FeatureName': 'RM', 'ValueAsString': '7.104'},\n",
       "  {'FeatureName': 'AGE', 'ValueAsString': '59.5'},\n",
       "  {'FeatureName': 'DIS', 'ValueAsString': '9.2229'},\n",
       "  {'FeatureName': 'RAD', 'ValueAsString': '3.0'},\n",
       "  {'FeatureName': 'TAX', 'ValueAsString': '216.0'},\n",
       "  {'FeatureName': 'PTRATIO', 'ValueAsString': '18.6'},\n",
       "  {'FeatureName': 'B', 'ValueAsString': '393.24'},\n",
       "  {'FeatureName': 'LSTAT', 'ValueAsString': '8.05'},\n",
       "  {'FeatureName': 'EventTime', 'ValueAsString': '1630618831.5963035'},\n",
       "  {'FeatureName': 'id', 'ValueAsString': '0'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = runtime.get_record(\n",
    "    FeatureGroupName=\"boston-features\",\n",
    "    RecordIdentifierValueAsString=\"0\"\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo we create a monitoring schedule for a deployed model. We'll begin by reloading our data from the previous demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "import pandas as pd\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data(test_split=0.1, seed=1234)\n",
    "headers = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"]\n",
    "\n",
    "\n",
    "train = pd.DataFrame(x_train, columns=headers)\n",
    "train[\"MEDV\"] = y_train\n",
    "\n",
    "# Target variable must come first per https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html\n",
    "train.set_index(train.pop('MEDV'), inplace=True)\n",
    "train.reset_index(inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  pd.DataFrame(x_test)\n",
    "test[\"MEDV\"] = y_test\n",
    "\n",
    "# Target variable must come first per https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html\n",
    "test.set_index(test.pop('MEDV'), inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the data to S3 as train and validation data, then train a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\", header=False, index=False)\n",
    "test.to_csv(\"validation.csv\", header=False, index=False)\n",
    "\n",
    "val_location = session.upload_data('./validation.csv', key_prefix=\"data\")\n",
    "train_location = session.upload_data('./train.csv', key_prefix=\"data\")\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "algo_image = sagemaker.image_uris.retrieve(\"xgboost\", region, version='latest')\n",
    "s3_output_location = f\"s3://{bucket}/models/boston_model\"\n",
    "\n",
    "model=sagemaker.estimator.Estimator(\n",
    "    image_uri=algo_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    volume_size=5,\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")\n",
    "\n",
    "model.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200)\n",
    "\n",
    "\n",
    "model.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the training job has finished, we can configure a deployment for data capture, then deploy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_uri = f's3://{bucket}/data-capture'\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=capture_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = model.deploy(\n",
    "    initial_instance_count=1, instance_type='ml.m4.xlarge',\n",
    "    data_capture_config=data_capture_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can provide some sample code to test the deployed model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.serializer = sagemaker.serializers.CSVSerializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = test.copy()\n",
    "inputs = inputs.drop(columns=inputs.columns[0])\n",
    "\n",
    "x_pred = xgb_predictor.predict(inputs.sample(5).values).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.inputs.TrainingInput at 0x7fa2bdd3ae48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the Model Monitor and suggest a baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "my_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_monitor.suggest_baseline(\n",
    "    baseline_dataset=f's3://{bucket}/data/train.csv',\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the Model Monitor must be scheduled, or it won't actually run regular processing jobs on the captured data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "my_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name='my-monitoring-schedule',\n",
    "    endpoint_input=xgb_predictor.endpoint_name,\n",
    "    statistics=my_monitor.baseline_statistics(),\n",
    "    constraints=my_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clarify\n",
    "\n",
    "This Clarify demo builds on the previous demo: we follow the same pattern of define-configure-schedule for our Monitor. Clarify, however, needs more config. We define `SHAPConfig`, `ModelConfig`, `ExplainabilityAnalysisConfig`, and pass them all to the scheduling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_monitor = sagemaker.model_monitor.ModelExplainabilityMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=session,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")\n",
    "\n",
    "\n",
    "shap_config = sagemaker.clarify.SHAPConfig(\n",
    "    baseline=[train.mean().astype(int).to_list()[1:]],\n",
    "    num_samples=int(x_train.size),\n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=False,\n",
    ")\n",
    "\n",
    "\n",
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=\"xgboost-2021-08-25-15-19-33-499\",\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    content_type=\"text/csv\",\n",
    "    accept_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "analysis_config = sagemaker.model_monitor.ExplainabilityAnalysisConfig(\n",
    "        explainability_config=shap_config,\n",
    "        model_config=model_config,\n",
    "        headers=train.columns.to_list()[1:],\n",
    "    )\n",
    "\n",
    "explainability_uri = f\"s3://{bucket}/model_explainability\"\n",
    "model_explainability_monitor.create_monitoring_schedule(\n",
    "    output_s3_uri=explainability_uri,\n",
    "    analysis_config=analysis_config,\n",
    "    endpoint_input=xgb_predictor.endpoint_name,\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting Monitoring Schedule with name: monitoring-schedule-2021-09-02-22-00-36-508\n"
     ]
    }
   ],
   "source": [
    "model_explainability_monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting Monitoring Schedule with name: my-monitoring-schedule\n"
     ]
    }
   ],
   "source": [
    "my_monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.1 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
